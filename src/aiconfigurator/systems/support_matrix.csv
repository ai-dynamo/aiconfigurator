Model,System,Backend,Version,Mode,Status,ErrMsg
DEEPSEEK_V3,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
DEEPSEEK_V3,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
DEEPSEEK_V3,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
DEEPSEEK_V3,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
DEEPSEEK_V3,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
DEEPSEEK_V3,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
DEEPSEEK_V3,h100_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 49, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 391, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 161, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 97, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 363, in query\n    assert self._attention_tp_size == 1 or self._attention_dp_size == 1, (\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: We don't enable the path for SGLang to support TP>1 and DP>1 for attn simultaneously\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: We don't enable the path for SGLang to support TP>1 and DP>1 for attn simultaneously\n"
DEEPSEEK_V3,h100_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 363, in query\n    assert self._attention_tp_size == 1 or self._attention_dp_size == 1, (\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: We don't enable the path for SGLang to support TP>1 and DP>1 for attn simultaneously\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: We don't enable the path for SGLang to support TP>1 and DP>1 for attn simultaneously\n"
DEEPSEEK_V3,h100_sxm,trtllm,0.20.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 171, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
DEEPSEEK_V3,h100_sxm,trtllm,0.20.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 530, in _get_summary_df\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
DEEPSEEK_V3,h100_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 171, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
DEEPSEEK_V3,h100_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 530, in _get_summary_df\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
DEEPSEEK_V3,h100_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
DEEPSEEK_V3,h100_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
DEEPSEEK_V3,h200_sxm,sglang,0.5.1.post1,agg,PASS,
DEEPSEEK_V3,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
DEEPSEEK_V3,h200_sxm,trtllm,0.20.0,agg,PASS,
DEEPSEEK_V3,h200_sxm,trtllm,0.20.0,disagg,PASS,
DEEPSEEK_V3,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
DEEPSEEK_V3,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
DEEPSEEK_V3,h200_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
DEEPSEEK_V3,h200_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
DEEPSEEK_V3,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
DEEPSEEK_V3,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,b200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,b200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,gb200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,gb200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 49, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 391, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 161, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 97, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,trtllm,0.20.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,trtllm,0.20.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
GPT_OSS_120B,h100_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
GPT_OSS_120B,h200_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 49, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 391, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 161, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 97, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,trtllm,0.20.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,trtllm,0.20.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
GPT_OSS_120B,h200_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
GPT_OSS_120B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,b200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,b200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,gb200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,gb200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 49, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 391, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 161, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 97, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,trtllm,0.20.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,trtllm,0.20.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
GPT_OSS_20B,h100_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
GPT_OSS_20B,h200_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 49, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 391, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 161, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 97, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,trtllm,0.20.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,trtllm,0.20.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
GPT_OSS_20B,h200_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
GPT_OSS_20B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 502, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2043, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1862, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1888, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
LLAMA2_13B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA2_13B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA2_13B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_13B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_13B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_13B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_13B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA2_13B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA2_13B,h100_sxm,trtllm,0.20.0,agg,PASS,
LLAMA2_13B,h100_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA2_13B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_13B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_13B,h100_sxm,vllm,0.11.0,agg,PASS,
LLAMA2_13B,h100_sxm,vllm,0.11.0,disagg,PASS,
LLAMA2_13B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA2_13B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA2_13B,h200_sxm,trtllm,0.20.0,agg,PASS,
LLAMA2_13B,h200_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA2_13B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_13B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_13B,h200_sxm,vllm,0.11.0,agg,PASS,
LLAMA2_13B,h200_sxm,vllm,0.11.0,disagg,PASS,
LLAMA2_13B,l40s,trtllm,1.0.0,agg,PASS,
LLAMA2_13B,l40s,trtllm,1.0.0,disagg,PASS,
LLAMA2_70B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA2_70B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA2_70B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_70B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_70B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_70B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_70B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA2_70B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA2_70B,h100_sxm,trtllm,0.20.0,agg,PASS,
LLAMA2_70B,h100_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA2_70B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_70B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_70B,h100_sxm,vllm,0.11.0,agg,PASS,
LLAMA2_70B,h100_sxm,vllm,0.11.0,disagg,PASS,
LLAMA2_70B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA2_70B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA2_70B,h200_sxm,trtllm,0.20.0,agg,PASS,
LLAMA2_70B,h200_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA2_70B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_70B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_70B,h200_sxm,vllm,0.11.0,agg,PASS,
LLAMA2_70B,h200_sxm,vllm,0.11.0,disagg,PASS,
LLAMA2_70B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 171, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
LLAMA2_70B,l40s,trtllm,1.0.0,disagg,PASS,
LLAMA2_7B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA2_7B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA2_7B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_7B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_7B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_7B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_7B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA2_7B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA2_7B,h100_sxm,trtllm,0.20.0,agg,PASS,
LLAMA2_7B,h100_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA2_7B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_7B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_7B,h100_sxm,vllm,0.11.0,agg,PASS,
LLAMA2_7B,h100_sxm,vllm,0.11.0,disagg,PASS,
LLAMA2_7B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA2_7B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA2_7B,h200_sxm,trtllm,0.20.0,agg,PASS,
LLAMA2_7B,h200_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA2_7B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_7B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_7B,h200_sxm,vllm,0.11.0,agg,PASS,
LLAMA2_7B,h200_sxm,vllm,0.11.0,disagg,PASS,
LLAMA2_7B,l40s,trtllm,1.0.0,agg,PASS,
LLAMA2_7B,l40s,trtllm,1.0.0,disagg,PASS,
LLAMA3.1_405B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 171, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
LLAMA3.1_405B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 530, in _get_summary_df\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
LLAMA3.1_405B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_405B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_405B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_405B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_405B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA3.1_405B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA3.1_405B,h100_sxm,trtllm,0.20.0,agg,PASS,
LLAMA3.1_405B,h100_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA3.1_405B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_405B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_405B,h100_sxm,vllm,0.11.0,agg,PASS,
LLAMA3.1_405B,h100_sxm,vllm,0.11.0,disagg,PASS,
LLAMA3.1_405B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA3.1_405B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA3.1_405B,h200_sxm,trtllm,0.20.0,agg,PASS,
LLAMA3.1_405B,h200_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA3.1_405B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_405B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_405B,h200_sxm,vllm,0.11.0,agg,PASS,
LLAMA3.1_405B,h200_sxm,vllm,0.11.0,disagg,PASS,
LLAMA3.1_405B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 171, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
LLAMA3.1_405B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 530, in _get_summary_df\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
LLAMA3.1_70B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA3.1_70B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA3.1_70B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_70B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_70B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_70B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_70B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA3.1_70B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA3.1_70B,h100_sxm,trtllm,0.20.0,agg,PASS,
LLAMA3.1_70B,h100_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA3.1_70B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_70B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_70B,h100_sxm,vllm,0.11.0,agg,PASS,
LLAMA3.1_70B,h100_sxm,vllm,0.11.0,disagg,PASS,
LLAMA3.1_70B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA3.1_70B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA3.1_70B,h200_sxm,trtllm,0.20.0,agg,PASS,
LLAMA3.1_70B,h200_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA3.1_70B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_70B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_70B,h200_sxm,vllm,0.11.0,agg,PASS,
LLAMA3.1_70B,h200_sxm,vllm,0.11.0,disagg,PASS,
LLAMA3.1_70B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 171, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
LLAMA3.1_70B,l40s,trtllm,1.0.0,disagg,PASS,
LLAMA3.1_8B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA3.1_8B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA3.1_8B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_8B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_8B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_8B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_8B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA3.1_8B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA3.1_8B,h100_sxm,trtllm,0.20.0,agg,PASS,
LLAMA3.1_8B,h100_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA3.1_8B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_8B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_8B,h100_sxm,vllm,0.11.0,agg,PASS,
LLAMA3.1_8B,h100_sxm,vllm,0.11.0,disagg,PASS,
LLAMA3.1_8B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA3.1_8B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA3.1_8B,h200_sxm,trtllm,0.20.0,agg,PASS,
LLAMA3.1_8B,h200_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA3.1_8B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_8B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_8B,h200_sxm,vllm,0.11.0,agg,PASS,
LLAMA3.1_8B,h200_sxm,vllm,0.11.0,disagg,PASS,
LLAMA3.1_8B,l40s,trtllm,1.0.0,agg,PASS,
LLAMA3.1_8B,l40s,trtllm,1.0.0,disagg,PASS,
MOE_Mixtral8x22B,a100_sxm,trtllm,1.0.0,agg,PASS,
MOE_Mixtral8x22B,a100_sxm,trtllm,1.0.0,disagg,PASS,
MOE_Mixtral8x22B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
MOE_Mixtral8x22B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
MOE_Mixtral8x22B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
MOE_Mixtral8x22B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
MOE_Mixtral8x22B,h100_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 49, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 391, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 161, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 97, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2614, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
MOE_Mixtral8x22B,h100_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2614, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
MOE_Mixtral8x22B,h100_sxm,trtllm,0.20.0,agg,PASS,
MOE_Mixtral8x22B,h100_sxm,trtllm,0.20.0,disagg,PASS,
MOE_Mixtral8x22B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
MOE_Mixtral8x22B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
MOE_Mixtral8x22B,h100_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
MOE_Mixtral8x22B,h100_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
MOE_Mixtral8x22B,h200_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 49, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 391, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 161, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 97, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2614, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
MOE_Mixtral8x22B,h200_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2614, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
MOE_Mixtral8x22B,h200_sxm,trtllm,0.20.0,agg,PASS,
MOE_Mixtral8x22B,h200_sxm,trtllm,0.20.0,disagg,PASS,
MOE_Mixtral8x22B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
MOE_Mixtral8x22B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
MOE_Mixtral8x22B,h200_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
MOE_Mixtral8x22B,h200_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
MOE_Mixtral8x22B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
MOE_Mixtral8x22B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
MOE_Mixtral8x7B,a100_sxm,trtllm,1.0.0,agg,PASS,
MOE_Mixtral8x7B,a100_sxm,trtllm,1.0.0,disagg,PASS,
MOE_Mixtral8x7B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
MOE_Mixtral8x7B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
MOE_Mixtral8x7B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
MOE_Mixtral8x7B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
MOE_Mixtral8x7B,h100_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 49, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 391, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 161, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 97, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2614, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
MOE_Mixtral8x7B,h100_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2614, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
MOE_Mixtral8x7B,h100_sxm,trtllm,0.20.0,agg,PASS,
MOE_Mixtral8x7B,h100_sxm,trtllm,0.20.0,disagg,PASS,
MOE_Mixtral8x7B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
MOE_Mixtral8x7B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
MOE_Mixtral8x7B,h100_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
MOE_Mixtral8x7B,h100_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
MOE_Mixtral8x7B,h200_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 49, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 391, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 161, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 97, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2614, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
MOE_Mixtral8x7B,h200_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2614, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
MOE_Mixtral8x7B,h200_sxm,trtllm,0.20.0,agg,PASS,
MOE_Mixtral8x7B,h200_sxm,trtllm,0.20.0,disagg,PASS,
MOE_Mixtral8x7B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
MOE_Mixtral8x7B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
MOE_Mixtral8x7B,h200_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
MOE_Mixtral8x7B,h200_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
MOE_Mixtral8x7B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
MOE_Mixtral8x7B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
Nemotron_super_v1.1,a100_sxm,trtllm,1.0.0,agg,PASS,
Nemotron_super_v1.1,a100_sxm,trtllm,1.0.0,disagg,PASS,
Nemotron_super_v1.1,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
Nemotron_super_v1.1,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
Nemotron_super_v1.1,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
Nemotron_super_v1.1,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
Nemotron_super_v1.1,h100_sxm,sglang,0.5.1.post1,agg,PASS,
Nemotron_super_v1.1,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
Nemotron_super_v1.1,h100_sxm,trtllm,0.20.0,agg,PASS,
Nemotron_super_v1.1,h100_sxm,trtllm,0.20.0,disagg,PASS,
Nemotron_super_v1.1,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
Nemotron_super_v1.1,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
Nemotron_super_v1.1,h100_sxm,vllm,0.11.0,agg,PASS,
Nemotron_super_v1.1,h100_sxm,vllm,0.11.0,disagg,PASS,
Nemotron_super_v1.1,h200_sxm,sglang,0.5.1.post1,agg,PASS,
Nemotron_super_v1.1,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
Nemotron_super_v1.1,h200_sxm,trtllm,0.20.0,agg,PASS,
Nemotron_super_v1.1,h200_sxm,trtllm,0.20.0,disagg,PASS,
Nemotron_super_v1.1,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
Nemotron_super_v1.1,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
Nemotron_super_v1.1,h200_sxm,vllm,0.11.0,agg,PASS,
Nemotron_super_v1.1,h200_sxm,vllm,0.11.0,disagg,PASS,
Nemotron_super_v1.1,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 171, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
Nemotron_super_v1.1,l40s,trtllm,1.0.0,disagg,PASS,
QWEN2.5_1.5B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN2.5_1.5B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN2.5_1.5B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_1.5B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_1.5B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_1.5B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_1.5B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_1.5B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_1.5B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_1.5B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_1.5B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_1.5B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_1.5B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_1.5B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_1.5B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_1.5B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_1.5B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_1.5B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_1.5B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_1.5B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_1.5B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_1.5B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_1.5B,l40s,trtllm,1.0.0,agg,PASS,
QWEN2.5_1.5B,l40s,trtllm,1.0.0,disagg,PASS,
QWEN2.5_32B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN2.5_32B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN2.5_32B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_32B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_32B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_32B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_32B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_32B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_32B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_32B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_32B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_32B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_32B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_32B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_32B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_32B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_32B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_32B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_32B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_32B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_32B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_32B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_32B,l40s,trtllm,1.0.0,agg,PASS,
QWEN2.5_32B,l40s,trtllm,1.0.0,disagg,PASS,
QWEN2.5_72B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN2.5_72B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN2.5_72B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_72B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_72B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_72B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_72B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_72B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_72B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_72B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_72B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_72B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_72B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_72B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_72B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_72B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_72B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_72B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_72B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_72B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_72B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_72B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_72B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 171, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
QWEN2.5_72B,l40s,trtllm,1.0.0,disagg,PASS,
QWEN2.5_7B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN2.5_7B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN2.5_7B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_7B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_7B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_7B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_7B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_7B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_7B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_7B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_7B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_7B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_7B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_7B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_7B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_7B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_7B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_7B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_7B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_7B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_7B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_7B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_7B,l40s,trtllm,1.0.0,agg,PASS,
QWEN2.5_7B,l40s,trtllm,1.0.0,disagg,PASS,
QWEN3_0.6B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_0.6B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_0.6B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_0.6B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_0.6B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_0.6B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_0.6B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_0.6B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_0.6B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_0.6B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_0.6B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_0.6B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_0.6B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN3_0.6B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_0.6B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_0.6B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_0.6B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_0.6B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_0.6B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_0.6B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_0.6B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN3_0.6B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_0.6B,l40s,trtllm,1.0.0,agg,PASS,
QWEN3_0.6B,l40s,trtllm,1.0.0,disagg,PASS,
QWEN3_1.7B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_1.7B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_1.7B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_1.7B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_1.7B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_1.7B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_1.7B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_1.7B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_1.7B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_1.7B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_1.7B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_1.7B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_1.7B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN3_1.7B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_1.7B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_1.7B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_1.7B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_1.7B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_1.7B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_1.7B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_1.7B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN3_1.7B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_1.7B,l40s,trtllm,1.0.0,agg,PASS,
QWEN3_1.7B,l40s,trtllm,1.0.0,disagg,PASS,
QWEN3_235B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_235B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_235B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_235B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_235B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_235B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_235B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_235B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_235B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_235B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_235B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_235B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_235B,h100_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
QWEN3_235B,h100_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
QWEN3_235B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_235B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_235B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_235B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_235B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_235B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_235B,h200_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
QWEN3_235B,h200_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
QWEN3_235B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_235B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,b200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,b200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,gb200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,gb200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 49, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 391, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 161, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 97, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2614, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2614, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,trtllm,0.20.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,trtllm,0.20.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
QWEN3_30B_A3B,h100_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
QWEN3_30B_A3B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_30B_A3B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_30B_A3B,h200_sxm,trtllm,0.20.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h200_sxm,trtllm,0.20.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_30B_A3B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_30B_A3B,h200_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
QWEN3_30B_A3B,h200_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
QWEN3_30B_A3B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_32B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_32B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_32B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_32B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_32B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_32B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_32B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_32B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_32B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_32B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_32B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_32B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_32B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN3_32B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_32B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_32B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_32B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_32B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_32B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_32B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_32B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN3_32B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_32B,l40s,trtllm,1.0.0,agg,PASS,
QWEN3_32B,l40s,trtllm,1.0.0,disagg,PASS,
QWEN3_480B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_480B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_480B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_480B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_480B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_480B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_480B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_480B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_480B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_480B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_480B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_480B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_480B,h100_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
QWEN3_480B,h100_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
QWEN3_480B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_480B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_480B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_480B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_480B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_480B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_480B,h200_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 241, in _agg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
QWEN3_480B,h200_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 762, in __init__\n    self.config, applied_layers = TaskConfigFactory.create(ctx)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 118, in create\n    _deep_merge(config_dict, layer.resolve(ctx))\n                             ^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 43, in resolve\n    payload = self.data(ctx) if callable(self.data) else self.data\n              ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 354, in _disagg_defaults_layer\n    raise NotImplementedError(""MoE is not implemented for vllm backend"")\nNotImplementedError: MoE is not implemented for vllm backend\n"
QWEN3_480B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 52, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 141, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 97, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 394, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 164, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 100, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1179, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1006, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 170, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_480B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 64, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 114, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 72, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2653, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(num_tokens, list(moe_dict.keys()), inner_only=False)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1785, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1181, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1142, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 278, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 671, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_8B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_8B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_8B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_8B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_8B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_8B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_8B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_8B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_8B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_8B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_8B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_8B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_8B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN3_8B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_8B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_8B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_8B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_8B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_8B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_8B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_8B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN3_8B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_8B,l40s,trtllm,1.0.0,agg,PASS,
QWEN3_8B,l40s,trtllm,1.0.0,disagg,PASS,
