# --- Optional: already inside the image ---
IN_CONTAINER=false

# --- Model paths ---
MODEL_LOCAL_DIR=/raid/hub/qwen3-32b-fp8
MODEL_HF_REPO=Qwen/Qwen3-32B-FP8

# --- Deployment knobs ---
SYSTEM=h200_sxm
MODEL=QWEN3_32B
VERSION=1.0.0rc3
GENERATED_CONFIG_VERSION=1.0.0rc6
VENV_PATH=/workspace/aic
ISL=5000
OSL=1000
TTFT=1000
TPOT=10
TOTAL_GPUS=8
HEAD_NODE_IP=0.0.0.0
PREFILL_FREE_GPU_MEM_FRAC=0.9
FREE_GPU_MEM_FRAC=0.7
DECODE_FREE_GPU_MEM_FRAC=0.5
PORT=8000
MODE=disagg

# --- Service naming ---
SERVED_MODEL_NAME=Qwen3/Qwen3-32B-FP8

# --- Container image ---
DYNAMO_IMAGE=nvcr.io/nvidia/ai-dynamo/tensorrtllm-runtime:0.5.0
TRTLLM_PIP=tensorrt-llm==1.0.0rc6
CONTAINER_NAME=dynamo-single-node

# --- Dynamo repo settings ---
# DYNAMO_DIR=/path/to/existing/dynamo  # Optional
DYNAMO_BRANCH=release/0.5.0
DYNAMO_GIT=https://github.com/ai-dynamo/dynamo

# --- Benchmarking settings ---
BENCHMARK_CONCURRENCY=auto   # can be auto or cc list likes BENCHMARK_CONCURRENCY="1 4 8 12 16 20"
#BENCHMARK_CONCURRENCY="1 2 4"

# --- Optional: download model if not present ---
ENABLE_MODEL_DOWNLOAD=true

# --- Optional: run-time save dir mapping for host ---
# SAVE_DIR_HOST=/workspace/aiconf_save
