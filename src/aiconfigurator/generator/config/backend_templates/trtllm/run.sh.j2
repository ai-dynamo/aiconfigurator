#!/bin/bash
set -e
trap 'echo "Cleaning up..."; kill 0 2>/dev/null || true' EXIT INT TERM

export MODEL_PATH=${MODEL_PATH:-"{{ ServiceConfig.model_path }}"}
export HF_TOKEN=${HF_TOKEN:-"{{ ServiceConfig.hf_token }}"}
export SERVED_MODEL_NAME=${SERVED_MODEL_NAME:-"{{ ServiceConfig.served_model_name }}"}
export HEAD_NODE_IP=${HEAD_NODE_IP:-"{{ ServiceConfig.head_node_ip }}"}
export ETCD_ENDPOINTS="${HEAD_NODE_IP}:2379"
export NATS_SERVER="nats://${HEAD_NODE_IP}:4222"

{% set enable_router = DynConfig.enable_router | default(false) %}

{% if ServiceConfig.include_frontend %}
python3 -m dynamo.frontend {% if enable_router %}--router-mode kv {% endif %}--http-port "{{ ServiceConfig.port }}" 2>&1 | sed "s/^/[Frontend] /" &
{% endif %}

{% if DynConfig.mode | default('disagg') == "agg" %}
AGG_GPU={{ agg_gpu }}
AGG_WORKERS={{ agg_workers }}
AGG_GPU_OFFSET={{ agg_gpu_offset | default(0) }}
for ((w=0; w<AGG_WORKERS; w++)); do
  BASE=$(( AGG_GPU_OFFSET + w * AGG_GPU ))
  GPU_LIST=$(seq -s, $BASE $((BASE+AGG_GPU-1)))
  ( CUDA_VISIBLE_DEVICES=$GPU_LIST python3 -m dynamo.trtllm \
    --model-path "$MODEL_PATH" \
    --served-model-name "$SERVED_MODEL_NAME" \
    --extra-engine-args "{{ agg_engine_args }}" \
    {% if enable_router %}--publish-events-and-metrics {% endif %} 2>&1 | sed "s/^/[Worker $w] /" ) &
done
wait
{% else %}
{% if prefill_workers|int > 0 %}
PREFILL_GPU={{ prefill_gpu }}
PREFILL_WORKERS={{ prefill_workers }}
for ((w=0; w<PREFILL_WORKERS; w++)); do
  BASE=$(( w * PREFILL_GPU ))
  GPU_LIST=$(seq -s, $BASE $((BASE+PREFILL_GPU-1)))
  ( CUDA_VISIBLE_DEVICES=$GPU_LIST python3 -m dynamo.trtllm \
    --model-path "$MODEL_PATH" \
    --served-model-name "$SERVED_MODEL_NAME" \
    --extra-engine-args "{{ prefill_engine_args }}" \
    --disaggregation-mode prefill \
    {% if enable_router %}--publish-events-and-metrics{% endif %} 2>&1 | sed "s/^/[Prefill $w] /" ) &
done
{% endif %}

{% if decode_workers|int > 0 %}
DECODE_GPU={{ decode_gpu }}
DECODE_WORKERS={{ decode_workers }}
DECODE_GPU_OFFSET={{ decode_gpu_offset | default(0) }}
for ((w=0; w<DECODE_WORKERS; w++)); do
  BASE=$(( DECODE_GPU_OFFSET + w * DECODE_GPU ))
  GPU_LIST=$(seq -s, $BASE $((BASE+DECODE_GPU-1)))
  ( CUDA_VISIBLE_DEVICES=$GPU_LIST python3 -m dynamo.trtllm \
    --model-path "$MODEL_PATH" \
    --served-model-name "$SERVED_MODEL_NAME" \
    --extra-engine-args "{{ decode_engine_args }}" \
    --disaggregation-mode decode 2>&1 | sed "s/^/[Decode $w] /" ) &
done
{% endif %}
wait
{% endif %}