Model,System,Backend,Version,Mode,Status,ErrMsg
DEEPSEEK_V3,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
DEEPSEEK_V3,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
DEEPSEEK_V3,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
DEEPSEEK_V3,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
DEEPSEEK_V3,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
DEEPSEEK_V3,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
DEEPSEEK_V3,h100_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 45, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 354, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 157, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 93, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 379, in query\n    assert self._attention_tp_size == 1 or self._attention_dp_size == 1, (\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: We don't enable the path for SGLang to support TP>1 and DP>1 for attn simultaneously\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: We don't enable the path for SGLang to support TP>1 and DP>1 for attn simultaneously\n"
DEEPSEEK_V3,h100_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 379, in query\n    assert self._attention_tp_size == 1 or self._attention_dp_size == 1, (\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: We don't enable the path for SGLang to support TP>1 and DP>1 for attn simultaneously\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: We don't enable the path for SGLang to support TP>1 and DP>1 for attn simultaneously\n"
DEEPSEEK_V3,h100_sxm,trtllm,0.20.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 143, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
DEEPSEEK_V3,h100_sxm,trtllm,0.20.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 501, in _get_summary_df\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
DEEPSEEK_V3,h100_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 143, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
DEEPSEEK_V3,h100_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 501, in _get_summary_df\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
DEEPSEEK_V3,h100_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 810, in __init__\n    self.validate()\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 819, in validate\n    raise NotImplementedError(""AIConfigurator does not yet support DEEPSEEK models for VLLM backend."")\nNotImplementedError: AIConfigurator does not yet support DEEPSEEK models for VLLM backend.\n"
DEEPSEEK_V3,h100_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 810, in __init__\n    self.validate()\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 819, in validate\n    raise NotImplementedError(""AIConfigurator does not yet support DEEPSEEK models for VLLM backend."")\nNotImplementedError: AIConfigurator does not yet support DEEPSEEK models for VLLM backend.\n"
DEEPSEEK_V3,h200_sxm,sglang,0.5.1.post1,agg,PASS,
DEEPSEEK_V3,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
DEEPSEEK_V3,h200_sxm,trtllm,0.20.0,agg,PASS,
DEEPSEEK_V3,h200_sxm,trtllm,0.20.0,disagg,PASS,
DEEPSEEK_V3,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
DEEPSEEK_V3,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
DEEPSEEK_V3,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
DEEPSEEK_V3,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
DEEPSEEK_V3,h200_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 810, in __init__\n    self.validate()\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 819, in validate\n    raise NotImplementedError(""AIConfigurator does not yet support DEEPSEEK models for VLLM backend."")\nNotImplementedError: AIConfigurator does not yet support DEEPSEEK models for VLLM backend.\n"
DEEPSEEK_V3,h200_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 113, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 810, in __init__\n    self.validate()\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 819, in validate\n    raise NotImplementedError(""AIConfigurator does not yet support DEEPSEEK models for VLLM backend."")\nNotImplementedError: AIConfigurator does not yet support DEEPSEEK models for VLLM backend.\n"
DEEPSEEK_V3,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
DEEPSEEK_V3,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,b200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,b200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,gb200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,gb200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 45, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 354, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 157, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 93, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,trtllm,0.20.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,trtllm,0.20.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 45, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 354, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 157, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 93, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,trtllm,0.20.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,trtllm,0.20.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,trtllm,1.2.0rc2,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,trtllm,1.2.0rc2,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,b200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,b200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,gb200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,gb200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 45, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 354, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 157, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 93, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,trtllm,0.20.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,trtllm,0.20.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 45, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 354, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 157, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 93, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,trtllm,0.20.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,trtllm,0.20.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,trtllm,1.2.0rc2,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,trtllm,1.2.0rc2,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,vllm,0.11.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/vllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,vllm,0.11.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 518, in query\n    database.query_context_attention(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2105, in query_context_attention\n    latency = self._interp_3d(n, full_s, b, attention_dict, ""cubic"") * prefix_correction\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1864, in _interp_3d\n    return self._interp_2d_1d(x, y, z, data, method)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1890, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
LLAMA2_13B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA2_13B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA2_13B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_13B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_13B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_13B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_13B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA2_13B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA2_13B,h100_sxm,trtllm,0.20.0,agg,PASS,
LLAMA2_13B,h100_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA2_13B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_13B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_13B,h100_sxm,vllm,0.11.0,agg,PASS,
LLAMA2_13B,h100_sxm,vllm,0.11.0,disagg,PASS,
LLAMA2_13B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA2_13B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA2_13B,h200_sxm,trtllm,0.20.0,agg,PASS,
LLAMA2_13B,h200_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA2_13B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_13B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_13B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
LLAMA2_13B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
LLAMA2_13B,h200_sxm,vllm,0.11.0,agg,PASS,
LLAMA2_13B,h200_sxm,vllm,0.11.0,disagg,PASS,
LLAMA2_13B,l40s,trtllm,1.0.0,agg,PASS,
LLAMA2_13B,l40s,trtllm,1.0.0,disagg,PASS,
LLAMA2_70B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA2_70B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA2_70B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_70B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_70B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_70B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_70B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA2_70B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA2_70B,h100_sxm,trtllm,0.20.0,agg,PASS,
LLAMA2_70B,h100_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA2_70B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_70B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_70B,h100_sxm,vllm,0.11.0,agg,PASS,
LLAMA2_70B,h100_sxm,vllm,0.11.0,disagg,PASS,
LLAMA2_70B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA2_70B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA2_70B,h200_sxm,trtllm,0.20.0,agg,PASS,
LLAMA2_70B,h200_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA2_70B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_70B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_70B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
LLAMA2_70B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
LLAMA2_70B,h200_sxm,vllm,0.11.0,agg,PASS,
LLAMA2_70B,h200_sxm,vllm,0.11.0,disagg,PASS,
LLAMA2_70B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 143, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
LLAMA2_70B,l40s,trtllm,1.0.0,disagg,PASS,
LLAMA2_7B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA2_7B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA2_7B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_7B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_7B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_7B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_7B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA2_7B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA2_7B,h100_sxm,trtllm,0.20.0,agg,PASS,
LLAMA2_7B,h100_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA2_7B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_7B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_7B,h100_sxm,vllm,0.11.0,agg,PASS,
LLAMA2_7B,h100_sxm,vllm,0.11.0,disagg,PASS,
LLAMA2_7B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA2_7B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA2_7B,h200_sxm,trtllm,0.20.0,agg,PASS,
LLAMA2_7B,h200_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA2_7B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_7B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_7B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
LLAMA2_7B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
LLAMA2_7B,h200_sxm,vllm,0.11.0,agg,PASS,
LLAMA2_7B,h200_sxm,vllm,0.11.0,disagg,PASS,
LLAMA2_7B,l40s,trtllm,1.0.0,agg,PASS,
LLAMA2_7B,l40s,trtllm,1.0.0,disagg,PASS,
LLAMA3.1_405B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 143, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
LLAMA3.1_405B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 501, in _get_summary_df\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
LLAMA3.1_405B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_405B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_405B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_405B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_405B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA3.1_405B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA3.1_405B,h100_sxm,trtllm,0.20.0,agg,PASS,
LLAMA3.1_405B,h100_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA3.1_405B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_405B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_405B,h100_sxm,vllm,0.11.0,agg,PASS,
LLAMA3.1_405B,h100_sxm,vllm,0.11.0,disagg,PASS,
LLAMA3.1_405B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA3.1_405B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA3.1_405B,h200_sxm,trtllm,0.20.0,agg,PASS,
LLAMA3.1_405B,h200_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA3.1_405B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_405B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_405B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
LLAMA3.1_405B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
LLAMA3.1_405B,h200_sxm,vllm,0.11.0,agg,PASS,
LLAMA3.1_405B,h200_sxm,vllm,0.11.0,disagg,PASS,
LLAMA3.1_405B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 143, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
LLAMA3.1_405B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 501, in _get_summary_df\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
LLAMA3.1_70B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA3.1_70B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA3.1_70B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_70B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_70B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_70B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_70B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA3.1_70B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA3.1_70B,h100_sxm,trtllm,0.20.0,agg,PASS,
LLAMA3.1_70B,h100_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA3.1_70B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_70B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_70B,h100_sxm,vllm,0.11.0,agg,PASS,
LLAMA3.1_70B,h100_sxm,vllm,0.11.0,disagg,PASS,
LLAMA3.1_70B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA3.1_70B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA3.1_70B,h200_sxm,trtllm,0.20.0,agg,PASS,
LLAMA3.1_70B,h200_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA3.1_70B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_70B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_70B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
LLAMA3.1_70B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
LLAMA3.1_70B,h200_sxm,vllm,0.11.0,agg,PASS,
LLAMA3.1_70B,h200_sxm,vllm,0.11.0,disagg,PASS,
LLAMA3.1_70B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 143, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
LLAMA3.1_70B,l40s,trtllm,1.0.0,disagg,PASS,
LLAMA3.1_8B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA3.1_8B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA3.1_8B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_8B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_8B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_8B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_8B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA3.1_8B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA3.1_8B,h100_sxm,trtllm,0.20.0,agg,PASS,
LLAMA3.1_8B,h100_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA3.1_8B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_8B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_8B,h100_sxm,vllm,0.11.0,agg,PASS,
LLAMA3.1_8B,h100_sxm,vllm,0.11.0,disagg,PASS,
LLAMA3.1_8B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
LLAMA3.1_8B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
LLAMA3.1_8B,h200_sxm,trtllm,0.20.0,agg,PASS,
LLAMA3.1_8B,h200_sxm,trtllm,0.20.0,disagg,PASS,
LLAMA3.1_8B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_8B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_8B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
LLAMA3.1_8B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
LLAMA3.1_8B,h200_sxm,vllm,0.11.0,agg,PASS,
LLAMA3.1_8B,h200_sxm,vllm,0.11.0,disagg,PASS,
LLAMA3.1_8B,l40s,trtllm,1.0.0,agg,PASS,
LLAMA3.1_8B,l40s,trtllm,1.0.0,disagg,PASS,
MOE_Mixtral8x22B,a100_sxm,trtllm,1.0.0,agg,PASS,
MOE_Mixtral8x22B,a100_sxm,trtllm,1.0.0,disagg,PASS,
MOE_Mixtral8x22B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
MOE_Mixtral8x22B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
MOE_Mixtral8x22B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
MOE_Mixtral8x22B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
MOE_Mixtral8x22B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
MOE_Mixtral8x22B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
MOE_Mixtral8x22B,h100_sxm,trtllm,0.20.0,agg,PASS,
MOE_Mixtral8x22B,h100_sxm,trtllm,0.20.0,disagg,PASS,
MOE_Mixtral8x22B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
MOE_Mixtral8x22B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
MOE_Mixtral8x22B,h100_sxm,vllm,0.11.0,agg,PASS,
MOE_Mixtral8x22B,h100_sxm,vllm,0.11.0,disagg,PASS,
MOE_Mixtral8x22B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
MOE_Mixtral8x22B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
MOE_Mixtral8x22B,h200_sxm,trtllm,0.20.0,agg,PASS,
MOE_Mixtral8x22B,h200_sxm,trtllm,0.20.0,disagg,PASS,
MOE_Mixtral8x22B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
MOE_Mixtral8x22B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
MOE_Mixtral8x22B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
MOE_Mixtral8x22B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
MOE_Mixtral8x22B,h200_sxm,vllm,0.11.0,agg,PASS,
MOE_Mixtral8x22B,h200_sxm,vllm,0.11.0,disagg,PASS,
MOE_Mixtral8x22B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
MOE_Mixtral8x22B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
MOE_Mixtral8x7B,a100_sxm,trtllm,1.0.0,agg,PASS,
MOE_Mixtral8x7B,a100_sxm,trtllm,1.0.0,disagg,PASS,
MOE_Mixtral8x7B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
MOE_Mixtral8x7B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
MOE_Mixtral8x7B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
MOE_Mixtral8x7B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
MOE_Mixtral8x7B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
MOE_Mixtral8x7B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
MOE_Mixtral8x7B,h100_sxm,trtllm,0.20.0,agg,PASS,
MOE_Mixtral8x7B,h100_sxm,trtllm,0.20.0,disagg,PASS,
MOE_Mixtral8x7B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
MOE_Mixtral8x7B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
MOE_Mixtral8x7B,h100_sxm,vllm,0.11.0,agg,PASS,
MOE_Mixtral8x7B,h100_sxm,vllm,0.11.0,disagg,PASS,
MOE_Mixtral8x7B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
MOE_Mixtral8x7B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
MOE_Mixtral8x7B,h200_sxm,trtllm,0.20.0,agg,PASS,
MOE_Mixtral8x7B,h200_sxm,trtllm,0.20.0,disagg,PASS,
MOE_Mixtral8x7B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
MOE_Mixtral8x7B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
MOE_Mixtral8x7B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
MOE_Mixtral8x7B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
MOE_Mixtral8x7B,h200_sxm,vllm,0.11.0,agg,PASS,
MOE_Mixtral8x7B,h200_sxm,vllm,0.11.0,disagg,PASS,
MOE_Mixtral8x7B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
MOE_Mixtral8x7B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
Nemotron_super_v1.1,a100_sxm,trtllm,1.0.0,agg,PASS,
Nemotron_super_v1.1,a100_sxm,trtllm,1.0.0,disagg,PASS,
Nemotron_super_v1.1,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
Nemotron_super_v1.1,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
Nemotron_super_v1.1,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
Nemotron_super_v1.1,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
Nemotron_super_v1.1,h100_sxm,sglang,0.5.1.post1,agg,PASS,
Nemotron_super_v1.1,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
Nemotron_super_v1.1,h100_sxm,trtllm,0.20.0,agg,PASS,
Nemotron_super_v1.1,h100_sxm,trtllm,0.20.0,disagg,PASS,
Nemotron_super_v1.1,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
Nemotron_super_v1.1,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
Nemotron_super_v1.1,h100_sxm,vllm,0.11.0,agg,PASS,
Nemotron_super_v1.1,h100_sxm,vllm,0.11.0,disagg,PASS,
Nemotron_super_v1.1,h200_sxm,sglang,0.5.1.post1,agg,PASS,
Nemotron_super_v1.1,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
Nemotron_super_v1.1,h200_sxm,trtllm,0.20.0,agg,PASS,
Nemotron_super_v1.1,h200_sxm,trtllm,0.20.0,disagg,PASS,
Nemotron_super_v1.1,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
Nemotron_super_v1.1,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
Nemotron_super_v1.1,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
Nemotron_super_v1.1,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
Nemotron_super_v1.1,h200_sxm,vllm,0.11.0,agg,PASS,
Nemotron_super_v1.1,h200_sxm,vllm,0.11.0,disagg,PASS,
Nemotron_super_v1.1,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 143, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
Nemotron_super_v1.1,l40s,trtllm,1.0.0,disagg,PASS,
QWEN2.5_1.5B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN2.5_1.5B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN2.5_1.5B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_1.5B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_1.5B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_1.5B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_1.5B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_1.5B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_1.5B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_1.5B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_1.5B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_1.5B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_1.5B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_1.5B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_1.5B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_1.5B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_1.5B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_1.5B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_1.5B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_1.5B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_1.5B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
QWEN2.5_1.5B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
QWEN2.5_1.5B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_1.5B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_1.5B,l40s,trtllm,1.0.0,agg,PASS,
QWEN2.5_1.5B,l40s,trtllm,1.0.0,disagg,PASS,
QWEN2.5_32B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN2.5_32B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN2.5_32B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_32B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_32B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_32B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_32B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_32B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_32B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_32B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_32B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_32B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_32B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_32B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_32B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_32B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_32B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_32B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_32B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_32B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_32B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
QWEN2.5_32B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
QWEN2.5_32B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_32B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_32B,l40s,trtllm,1.0.0,agg,PASS,
QWEN2.5_32B,l40s,trtllm,1.0.0,disagg,PASS,
QWEN2.5_72B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN2.5_72B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN2.5_72B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_72B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_72B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_72B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_72B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_72B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_72B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_72B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_72B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_72B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_72B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_72B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_72B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_72B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_72B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_72B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_72B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_72B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_72B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
QWEN2.5_72B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
QWEN2.5_72B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_72B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_72B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 143, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
QWEN2.5_72B,l40s,trtllm,1.0.0,disagg,PASS,
QWEN2.5_7B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN2.5_7B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN2.5_7B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_7B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_7B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_7B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_7B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_7B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_7B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_7B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_7B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_7B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_7B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_7B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_7B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN2.5_7B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN2.5_7B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN2.5_7B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN2.5_7B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_7B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_7B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
QWEN2.5_7B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
QWEN2.5_7B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN2.5_7B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN2.5_7B,l40s,trtllm,1.0.0,agg,PASS,
QWEN2.5_7B,l40s,trtllm,1.0.0,disagg,PASS,
QWEN3_0.6B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_0.6B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_0.6B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_0.6B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_0.6B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_0.6B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_0.6B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_0.6B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_0.6B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_0.6B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_0.6B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_0.6B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_0.6B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN3_0.6B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_0.6B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_0.6B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_0.6B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_0.6B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_0.6B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_0.6B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_0.6B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
QWEN3_0.6B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
QWEN3_0.6B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN3_0.6B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_0.6B,l40s,trtllm,1.0.0,agg,PASS,
QWEN3_0.6B,l40s,trtllm,1.0.0,disagg,PASS,
QWEN3_1.7B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_1.7B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_1.7B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_1.7B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_1.7B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_1.7B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_1.7B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_1.7B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_1.7B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_1.7B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_1.7B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_1.7B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_1.7B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN3_1.7B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_1.7B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_1.7B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_1.7B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_1.7B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_1.7B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_1.7B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_1.7B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
QWEN3_1.7B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
QWEN3_1.7B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN3_1.7B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_1.7B,l40s,trtllm,1.0.0,agg,PASS,
QWEN3_1.7B,l40s,trtllm,1.0.0,disagg,PASS,
QWEN3_235B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_235B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_235B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_235B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_235B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_235B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_235B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_235B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_235B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_235B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_235B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_235B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_235B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN3_235B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_235B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_235B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_235B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_235B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_235B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_235B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_235B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
QWEN3_235B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
QWEN3_235B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN3_235B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_235B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_235B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,b200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,b200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,gb200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,gb200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,sglang,0.5.1.post1,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 45, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 354, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 157, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/sglang_backend.py"", line 93, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2977, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,sglang,0.5.1.post1,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 2977, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,trtllm,0.20.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,trtllm,0.20.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN3_30B_A3B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_30B_A3B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_30B_A3B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_30B_A3B,h200_sxm,trtllm,0.20.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h200_sxm,trtllm,0.20.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_30B_A3B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_30B_A3B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
QWEN3_30B_A3B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
QWEN3_30B_A3B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN3_30B_A3B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_30B_A3B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_32B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_32B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_32B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_32B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_32B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_32B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_32B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_32B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_32B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_32B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_32B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_32B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_32B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN3_32B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_32B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_32B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_32B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_32B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_32B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_32B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_32B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
QWEN3_32B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
QWEN3_32B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN3_32B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_32B,l40s,trtllm,1.0.0,agg,PASS,
QWEN3_32B,l40s,trtllm,1.0.0,disagg,PASS,
QWEN3_480B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_480B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_480B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_480B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_480B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_480B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_480B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_480B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_480B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_480B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_480B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_480B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_480B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN3_480B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_480B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_480B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_480B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_480B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_480B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_480B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_480B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
QWEN3_480B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
QWEN3_480B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN3_480B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_480B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 356, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 159, in run_agg\n    mix_step_latency = _get_mix_step_latency(\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 95, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1169, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 991, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_480B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 478, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 115, in run_static\n    context_latency_dict = _run_context(batch_size, isl, prefix)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/backends/base_backend.py"", line 73, in _run_context\n    latency = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/operations.py"", line 181, in query\n    database.query_moe(\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 3024, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/perf_database.py"", line 1787, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""/home/harrli/Projects/aiconfigurator/tests/sdk/support_matrix/suppport_matrix.py"", line 117, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1171, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/task.py"", line 1137, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 638, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""/home/harrli/Projects/aiconfigurator/src/aiconfigurator/sdk/inference_session.py"", line 500, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_8B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_8B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_8B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_8B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_8B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_8B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_8B,h100_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_8B,h100_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_8B,h100_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_8B,h100_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_8B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_8B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_8B,h100_sxm,vllm,0.11.0,agg,PASS,
QWEN3_8B,h100_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_8B,h200_sxm,sglang,0.5.1.post1,agg,PASS,
QWEN3_8B,h200_sxm,sglang,0.5.1.post1,disagg,PASS,
QWEN3_8B,h200_sxm,trtllm,0.20.0,agg,PASS,
QWEN3_8B,h200_sxm,trtllm,0.20.0,disagg,PASS,
QWEN3_8B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_8B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_8B,h200_sxm,trtllm,1.2.0rc2,agg,PASS,
QWEN3_8B,h200_sxm,trtllm,1.2.0rc2,disagg,PASS,
QWEN3_8B,h200_sxm,vllm,0.11.0,agg,PASS,
QWEN3_8B,h200_sxm,vllm,0.11.0,disagg,PASS,
QWEN3_8B,l40s,trtllm,1.0.0,agg,PASS,
QWEN3_8B,l40s,trtllm,1.0.0,disagg,PASS,
